{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_time</th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_line_num</th>\n",
       "      <th>virtual_transaction_id</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>query_template</th>\n",
       "      <th>query_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-25 07:12:57.362167</td>\n",
       "      <td>4811356</td>\n",
       "      <td>0</td>\n",
       "      <td>AAC/4811356/0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-06-25 07:12:57.685996</td>\n",
       "      <td>4811357</td>\n",
       "      <td>0</td>\n",
       "      <td>AAC/4811357/0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-06-25 07:12:57.686190</td>\n",
       "      <td>4811357</td>\n",
       "      <td>1</td>\n",
       "      <td>AAC/4811357/1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-06-25 07:12:57.686832</td>\n",
       "      <td>4811357</td>\n",
       "      <td>2</td>\n",
       "      <td>AAC/4811357/2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT expdate,expdate2 FROM systemenv where d...</td>\n",
       "      <td>('1',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-06-25 07:12:57.695170</td>\n",
       "      <td>4811357</td>\n",
       "      <td>3</td>\n",
       "      <td>AAC/4811357/3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>select content from content where name= $1 and...</td>\n",
       "      <td>(\"'15\\\\5d3afff71fda95c45e666b77095523a5'\", '1')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-06-25 07:12:57.697223</td>\n",
       "      <td>4811357</td>\n",
       "      <td>4</td>\n",
       "      <td>AAC/4811357/4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-06-25 07:18:19.799453</td>\n",
       "      <td>4811358</td>\n",
       "      <td>0</td>\n",
       "      <td>AAC/4811358/0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-06-25 07:18:19.799775</td>\n",
       "      <td>4811358</td>\n",
       "      <td>1</td>\n",
       "      <td>AAC/4811358/1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-06-25 07:18:19.803895</td>\n",
       "      <td>4811358</td>\n",
       "      <td>2</td>\n",
       "      <td>AAC/4811358/2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT programs.id FROM programs INNER JOIN lu...</td>\n",
       "      <td>('1', '1')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-06-25 07:18:19.804219</td>\n",
       "      <td>4811358</td>\n",
       "      <td>3</td>\n",
       "      <td>AAC/4811358/3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT name from domain where id = $1</td>\n",
       "      <td>('1',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-06-25 07:18:19.804533</td>\n",
       "      <td>4811358</td>\n",
       "      <td>4</td>\n",
       "      <td>AAC/4811358/4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT name from domain where id = $1</td>\n",
       "      <td>('1',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-06-25 07:18:19.813278</td>\n",
       "      <td>4811359</td>\n",
       "      <td>0</td>\n",
       "      <td>AAC/4811359/0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-06-25 07:18:19.813598</td>\n",
       "      <td>4811359</td>\n",
       "      <td>1</td>\n",
       "      <td>AAC/4811359/1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-06-25 07:18:19.814539</td>\n",
       "      <td>4811359</td>\n",
       "      <td>2</td>\n",
       "      <td>AAC/4811359/2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT domain_unit.* FROM domain_unit WHERE do...</td>\n",
       "      <td>('1',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-06-25 07:18:19.815449</td>\n",
       "      <td>4811359</td>\n",
       "      <td>3</td>\n",
       "      <td>AAC/4811359/3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT unit.* FROM unit WHERE unit_id = $1</td>\n",
       "      <td>('1',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-06-25 07:18:19.816266</td>\n",
       "      <td>4811359</td>\n",
       "      <td>4</td>\n",
       "      <td>AAC/4811359/4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT program.* FROM program WHERE program.un...</td>\n",
       "      <td>('1',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017-06-25 07:18:19.817100</td>\n",
       "      <td>4811359</td>\n",
       "      <td>5</td>\n",
       "      <td>AAC/4811359/5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT unit.* FROM unit WHERE parent_unit_id = $1</td>\n",
       "      <td>('1',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-06-25 07:18:19.817964</td>\n",
       "      <td>4811359</td>\n",
       "      <td>6</td>\n",
       "      <td>AAC/4811359/6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT domain_unit.* FROM domain_unit WHERE un...</td>\n",
       "      <td>('1',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017-06-25 07:18:19.818720</td>\n",
       "      <td>4811359</td>\n",
       "      <td>7</td>\n",
       "      <td>AAC/4811359/7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT department_unit.* FROM department_unit ...</td>\n",
       "      <td>('1',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017-06-25 07:18:19.819512</td>\n",
       "      <td>4811359</td>\n",
       "      <td>8</td>\n",
       "      <td>AAC/4811359/8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT programs_unit.* FROM programs_unit WHER...</td>\n",
       "      <td>('1',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017-06-25 07:18:19.820255</td>\n",
       "      <td>4811359</td>\n",
       "      <td>9</td>\n",
       "      <td>AAC/4811359/9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT period.* FROM period WHERE unit_id = $1...</td>\n",
       "      <td>('1', '1')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-06-25 07:18:19.822910</td>\n",
       "      <td>4811359</td>\n",
       "      <td>10</td>\n",
       "      <td>AAC/4811359/10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT period.* FROM period WHERE period_id = ...</td>\n",
       "      <td>('1357',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017-06-25 07:18:19.825169</td>\n",
       "      <td>4811359</td>\n",
       "      <td>11</td>\n",
       "      <td>AAC/4811359/11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT * FROM period_umbrella WHERE period_id ...</td>\n",
       "      <td>(\"'1357'\", '1')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017-06-25 07:18:19.826005</td>\n",
       "      <td>4811359</td>\n",
       "      <td>12</td>\n",
       "      <td>AAC/4811359/12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT period.* FROM period WHERE unit_id = $1...</td>\n",
       "      <td>('1', '1357')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-06-25 07:18:19.826795</td>\n",
       "      <td>4811359</td>\n",
       "      <td>13</td>\n",
       "      <td>AAC/4811359/13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT program_group.* FROM program_group WHER...</td>\n",
       "      <td>(\"'1357'\",)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017-06-25 07:18:19.827561</td>\n",
       "      <td>4811359</td>\n",
       "      <td>14</td>\n",
       "      <td>AAC/4811359/14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT period_program.* FROM period_program WH...</td>\n",
       "      <td>('1357',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017-06-25 07:18:19.828327</td>\n",
       "      <td>4811359</td>\n",
       "      <td>15</td>\n",
       "      <td>AAC/4811359/15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT * FROM period_application WHERE period_...</td>\n",
       "      <td>('1357',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017-06-25 07:18:19.830431</td>\n",
       "      <td>4811359</td>\n",
       "      <td>16</td>\n",
       "      <td>AAC/4811359/16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT period.* FROM period WHERE period_id = ...</td>\n",
       "      <td>('1349',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2017-06-25 07:18:19.832458</td>\n",
       "      <td>4811359</td>\n",
       "      <td>17</td>\n",
       "      <td>AAC/4811359/17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT * FROM period_umbrella WHERE period_id ...</td>\n",
       "      <td>(\"'1349'\", '1')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017-06-25 07:18:19.833279</td>\n",
       "      <td>4811359</td>\n",
       "      <td>18</td>\n",
       "      <td>AAC/4811359/18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT period.* FROM period WHERE unit_id = $1...</td>\n",
       "      <td>('1', '1349')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2017-06-25 07:18:19.834123</td>\n",
       "      <td>4811359</td>\n",
       "      <td>19</td>\n",
       "      <td>AAC/4811359/19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT program_group.* FROM program_group WHER...</td>\n",
       "      <td>(\"'1349'\",)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2017-06-25 07:18:19.834938</td>\n",
       "      <td>4811359</td>\n",
       "      <td>20</td>\n",
       "      <td>AAC/4811359/20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT period_program.* FROM period_program WH...</td>\n",
       "      <td>('1349',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2017-06-25 07:18:19.835755</td>\n",
       "      <td>4811359</td>\n",
       "      <td>21</td>\n",
       "      <td>AAC/4811359/21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT * FROM period_application WHERE period_...</td>\n",
       "      <td>('1349',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2017-06-25 07:18:19.837890</td>\n",
       "      <td>4811359</td>\n",
       "      <td>22</td>\n",
       "      <td>AAC/4811359/22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT period.* FROM period WHERE period_id = ...</td>\n",
       "      <td>('1315',)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2017-06-25 07:18:19.839808</td>\n",
       "      <td>4811359</td>\n",
       "      <td>23</td>\n",
       "      <td>AAC/4811359/23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT * FROM period_umbrella WHERE period_id ...</td>\n",
       "      <td>(\"'1315'\", '1')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2017-06-25 07:18:19.840594</td>\n",
       "      <td>4811359</td>\n",
       "      <td>24</td>\n",
       "      <td>AAC/4811359/24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT period.* FROM period WHERE unit_id = $1...</td>\n",
       "      <td>('1', '1315')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2017-06-25 07:18:19.841387</td>\n",
       "      <td>4811359</td>\n",
       "      <td>25</td>\n",
       "      <td>AAC/4811359/25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SELECT program_group.* FROM program_group WHER...</td>\n",
       "      <td>(\"'1315'\",)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      log_time  session_id  session_line_num  \\\n",
       "0   2017-06-25 07:12:57.362167     4811356                 0   \n",
       "1   2017-06-25 07:12:57.685996     4811357                 0   \n",
       "2   2017-06-25 07:12:57.686190     4811357                 1   \n",
       "3   2017-06-25 07:12:57.686832     4811357                 2   \n",
       "4   2017-06-25 07:12:57.695170     4811357                 3   \n",
       "5   2017-06-25 07:12:57.697223     4811357                 4   \n",
       "6   2017-06-25 07:18:19.799453     4811358                 0   \n",
       "7   2017-06-25 07:18:19.799775     4811358                 1   \n",
       "8   2017-06-25 07:18:19.803895     4811358                 2   \n",
       "9   2017-06-25 07:18:19.804219     4811358                 3   \n",
       "10  2017-06-25 07:18:19.804533     4811358                 4   \n",
       "11  2017-06-25 07:18:19.813278     4811359                 0   \n",
       "12  2017-06-25 07:18:19.813598     4811359                 1   \n",
       "13  2017-06-25 07:18:19.814539     4811359                 2   \n",
       "14  2017-06-25 07:18:19.815449     4811359                 3   \n",
       "15  2017-06-25 07:18:19.816266     4811359                 4   \n",
       "16  2017-06-25 07:18:19.817100     4811359                 5   \n",
       "17  2017-06-25 07:18:19.817964     4811359                 6   \n",
       "18  2017-06-25 07:18:19.818720     4811359                 7   \n",
       "19  2017-06-25 07:18:19.819512     4811359                 8   \n",
       "20  2017-06-25 07:18:19.820255     4811359                 9   \n",
       "21  2017-06-25 07:18:19.822910     4811359                10   \n",
       "22  2017-06-25 07:18:19.825169     4811359                11   \n",
       "23  2017-06-25 07:18:19.826005     4811359                12   \n",
       "24  2017-06-25 07:18:19.826795     4811359                13   \n",
       "25  2017-06-25 07:18:19.827561     4811359                14   \n",
       "26  2017-06-25 07:18:19.828327     4811359                15   \n",
       "27  2017-06-25 07:18:19.830431     4811359                16   \n",
       "28  2017-06-25 07:18:19.832458     4811359                17   \n",
       "29  2017-06-25 07:18:19.833279     4811359                18   \n",
       "30  2017-06-25 07:18:19.834123     4811359                19   \n",
       "31  2017-06-25 07:18:19.834938     4811359                20   \n",
       "32  2017-06-25 07:18:19.835755     4811359                21   \n",
       "33  2017-06-25 07:18:19.837890     4811359                22   \n",
       "34  2017-06-25 07:18:19.839808     4811359                23   \n",
       "35  2017-06-25 07:18:19.840594     4811359                24   \n",
       "36  2017-06-25 07:18:19.841387     4811359                25   \n",
       "\n",
       "   virtual_transaction_id  transaction_id  \\\n",
       "0           AAC/4811356/0             NaN   \n",
       "1           AAC/4811357/0             NaN   \n",
       "2           AAC/4811357/1             NaN   \n",
       "3           AAC/4811357/2             NaN   \n",
       "4           AAC/4811357/3             NaN   \n",
       "5           AAC/4811357/4             NaN   \n",
       "6           AAC/4811358/0             NaN   \n",
       "7           AAC/4811358/1             NaN   \n",
       "8           AAC/4811358/2             NaN   \n",
       "9           AAC/4811358/3             NaN   \n",
       "10          AAC/4811358/4             NaN   \n",
       "11          AAC/4811359/0             NaN   \n",
       "12          AAC/4811359/1             NaN   \n",
       "13          AAC/4811359/2             NaN   \n",
       "14          AAC/4811359/3             NaN   \n",
       "15          AAC/4811359/4             NaN   \n",
       "16          AAC/4811359/5             NaN   \n",
       "17          AAC/4811359/6             NaN   \n",
       "18          AAC/4811359/7             NaN   \n",
       "19          AAC/4811359/8             NaN   \n",
       "20          AAC/4811359/9             NaN   \n",
       "21         AAC/4811359/10             NaN   \n",
       "22         AAC/4811359/11             NaN   \n",
       "23         AAC/4811359/12             NaN   \n",
       "24         AAC/4811359/13             NaN   \n",
       "25         AAC/4811359/14             NaN   \n",
       "26         AAC/4811359/15             NaN   \n",
       "27         AAC/4811359/16             NaN   \n",
       "28         AAC/4811359/17             NaN   \n",
       "29         AAC/4811359/18             NaN   \n",
       "30         AAC/4811359/19             NaN   \n",
       "31         AAC/4811359/20             NaN   \n",
       "32         AAC/4811359/21             NaN   \n",
       "33         AAC/4811359/22             NaN   \n",
       "34         AAC/4811359/23             NaN   \n",
       "35         AAC/4811359/24             NaN   \n",
       "36         AAC/4811359/25             NaN   \n",
       "\n",
       "                                       query_template  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3   SELECT expdate,expdate2 FROM systemenv where d...   \n",
       "4   select content from content where name= $1 and...   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8   SELECT programs.id FROM programs INNER JOIN lu...   \n",
       "9               SELECT name from domain where id = $1   \n",
       "10              SELECT name from domain where id = $1   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13  SELECT domain_unit.* FROM domain_unit WHERE do...   \n",
       "14         SELECT unit.* FROM unit WHERE unit_id = $1   \n",
       "15  SELECT program.* FROM program WHERE program.un...   \n",
       "16  SELECT unit.* FROM unit WHERE parent_unit_id = $1   \n",
       "17  SELECT domain_unit.* FROM domain_unit WHERE un...   \n",
       "18  SELECT department_unit.* FROM department_unit ...   \n",
       "19  SELECT programs_unit.* FROM programs_unit WHER...   \n",
       "20  SELECT period.* FROM period WHERE unit_id = $1...   \n",
       "21  SELECT period.* FROM period WHERE period_id = ...   \n",
       "22  SELECT * FROM period_umbrella WHERE period_id ...   \n",
       "23  SELECT period.* FROM period WHERE unit_id = $1...   \n",
       "24  SELECT program_group.* FROM program_group WHER...   \n",
       "25  SELECT period_program.* FROM period_program WH...   \n",
       "26  SELECT * FROM period_application WHERE period_...   \n",
       "27  SELECT period.* FROM period WHERE period_id = ...   \n",
       "28  SELECT * FROM period_umbrella WHERE period_id ...   \n",
       "29  SELECT period.* FROM period WHERE unit_id = $1...   \n",
       "30  SELECT program_group.* FROM program_group WHER...   \n",
       "31  SELECT period_program.* FROM period_program WH...   \n",
       "32  SELECT * FROM period_application WHERE period_...   \n",
       "33  SELECT period.* FROM period WHERE period_id = ...   \n",
       "34  SELECT * FROM period_umbrella WHERE period_id ...   \n",
       "35  SELECT period.* FROM period WHERE unit_id = $1...   \n",
       "36  SELECT program_group.* FROM program_group WHER...   \n",
       "\n",
       "                                       query_params  \n",
       "0                                                ()  \n",
       "1                                                ()  \n",
       "2                                                ()  \n",
       "3                                            ('1',)  \n",
       "4   (\"'15\\\\5d3afff71fda95c45e666b77095523a5'\", '1')  \n",
       "5                                                ()  \n",
       "6                                                ()  \n",
       "7                                                ()  \n",
       "8                                        ('1', '1')  \n",
       "9                                            ('1',)  \n",
       "10                                           ('1',)  \n",
       "11                                               ()  \n",
       "12                                               ()  \n",
       "13                                           ('1',)  \n",
       "14                                           ('1',)  \n",
       "15                                           ('1',)  \n",
       "16                                           ('1',)  \n",
       "17                                           ('1',)  \n",
       "18                                           ('1',)  \n",
       "19                                           ('1',)  \n",
       "20                                       ('1', '1')  \n",
       "21                                        ('1357',)  \n",
       "22                                  (\"'1357'\", '1')  \n",
       "23                                    ('1', '1357')  \n",
       "24                                      (\"'1357'\",)  \n",
       "25                                        ('1357',)  \n",
       "26                                        ('1357',)  \n",
       "27                                        ('1349',)  \n",
       "28                                  (\"'1349'\", '1')  \n",
       "29                                    ('1', '1349')  \n",
       "30                                      (\"'1349'\",)  \n",
       "31                                        ('1349',)  \n",
       "32                                        ('1349',)  \n",
       "33                                        ('1315',)  \n",
       "34                                  (\"'1315'\", '1')  \n",
       "35                                    ('1', '1315')  \n",
       "36                                      (\"'1315'\",)  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(\"parsed_admission/postgres_parsed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics.pairwise\n",
    "import sklearn.neighbors\n",
    "import sklearn.preprocessing\n",
    "from plumbum import cli\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from constants import DEBUG_POSTGRESQL_CSV_PARSED\n",
    "\n",
    "\n",
    "class Clusterer:\n",
    "    \"\"\"\n",
    "    Cluster query templates based on the algorithms from QueryBot5000.\n",
    "\n",
    "    [QueryBot5000]\n",
    "    Lin Ma, Dana Van Aken, Ahmed Hefny, Gustavo Mezerhane, Andrew Pavlo,\n",
    "    and Geoffrey J. Gordon. 2018. Query-based Workload Forecasting for\n",
    "    Self-Driving Database Management Systems. SIGMOD 2018.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    _df : pd.Dataframe\n",
    "        Dataframe of counts grouped by (template, log_time_s)\n",
    "        where log_time_s is aggregated to the clustering_interval\n",
    "    n_samples : int\n",
    "        Number of samples to use for calculating similarity between arrival rates.\n",
    "    rho : float\n",
    "        Similarity threshold used to determine template cluster membership.\n",
    "    min_time : pd.Timestamp\n",
    "        Earliest timestamp seen in _df.\n",
    "    max_time : pd.Timestamp\n",
    "        Latest timestamp seen in _df.\n",
    "    cluster_interval : pd.Timedelta\n",
    "        Time interval the df is aggregated by.\n",
    "    n : int\n",
    "        Number of datapoints in _df.\n",
    "    cluster_gap : int\n",
    "        Only use every x \"time steps\" to iterate for online clustering.\n",
    "    n_gaps : int\n",
    "        Number of time steps to to run online clustering.\n",
    "    _dbgname : dict (string:int)\n",
    "        Reverse lookup from query template string to an id.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, dataframe, n_samples=10000, rho=0.8, cluster_interval=pd.Timedelta(seconds=1),\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Cluster the provided dataframe according to QueryBot5000.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataframe : pd.DataFrame\n",
    "            Dataframe containing the query templates to be clustered.\n",
    "        n_samples : int\n",
    "            The number of timestamps to sample.\n",
    "        rho : float\n",
    "            Cosine similarity threshold for query template clustering.\n",
    "        cluster_interval : pd.TimeDelta\n",
    "            Time interval to group and count the query templates.\n",
    "        \"\"\"\n",
    "        assert dataframe.index.names == [\"query_template\", \"log_time_s\"]\n",
    "        assert dataframe.columns.values == [\"count\"]\n",
    "        self._df = dataframe\n",
    "        self.n_samples = n_samples\n",
    "        self.rho = rho\n",
    "\n",
    "        # Cluster interval of every second.\n",
    "        self.min_time = self._get_timestamps().min()\n",
    "        self.max_time = self._get_timestamps().max()\n",
    "\n",
    "        self.interval_delta = cluster_interval\n",
    "        self.n = int((self.max_time - self.min_time) / self.interval_delta + 1)\n",
    "\n",
    "        self.cluster_gap = 1\n",
    "        self.n_gaps = self.n // self.cluster_gap + 1\n",
    "\n",
    "        # Represent query templates with integers for concise readability.\n",
    "        self._dbgname = {\n",
    "            template_str: template_id for template_id, template_str in dict(enumerate(self._get_queries())).items()\n",
    "        }\n",
    "\n",
    "        # Cluster the queries.\n",
    "        self.assignment_df = self._cluster_offline()\n",
    "\n",
    "    def _get_queries(self):\n",
    "        \"\"\"\n",
    "        Get the query templates being clustered.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        queries : List[str]\n",
    "            A list of the query templates being clustered.\n",
    "        \"\"\"\n",
    "        return sorted(set(self._df.index.get_level_values(0)))\n",
    "\n",
    "    def _get_timestamps(self):\n",
    "        \"\"\"\n",
    "        Get all the timestamps across all the query templates.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        timestamps : pd.DatetimeIndex\n",
    "            All the timestamps.\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO(Mike): Are we ever relying on the date time index here to\n",
    "        # reconstruct the time series with the clustering interval?\n",
    "        # Could anything go wrong if this only has\n",
    "        # 00:00, 00:01, 00:03, 00:04, but missing 00:02?\n",
    "        return self._df.index.get_level_values(1)\n",
    "\n",
    "    def _get_first_arrival(self, template):\n",
    "        \"\"\"\n",
    "        Find the first arrival time for the given query.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        template : str\n",
    "            The query template to find the first arrival time for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        first_arrival : pd.Timestamp\n",
    "            The first timestamp for the given query template.\n",
    "        \"\"\"\n",
    "        return self._df.xs(template, level=0).index.min()\n",
    "\n",
    "    @staticmethod\n",
    "    def _query_df_range(df, template, start_time, end_time):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df\n",
    "        template\n",
    "        start_time\n",
    "        end_time\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        results : pd.DataFrame\n",
    "        \"\"\"\n",
    "        # The first level can be dropped since query_template == template.\n",
    "        return df.query(\n",
    "            \"`query_template` == @template and @start_time <= `log_time_s` and `log_time_s` < @end_time\"\n",
    "        ).droplevel(0)\n",
    "\n",
    "    @staticmethod\n",
    "    def _query_df(df, template, timestamps):\n",
    "        \"\"\"\n",
    "        Get template counts, sampled by timestamps\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df\n",
    "        template\n",
    "        timestamps\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        results : pd.DataFrame\n",
    "        \"\"\"\n",
    "        # The first level can be dropped since query_template == template.\n",
    "        df = df.query(\"`query_template` == @template and `log_time_s` in @timestamps\").droplevel(0)\n",
    "        return df.reindex(timestamps, fill_value=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def _query_series(series, timestamps):\n",
    "        \"\"\"\n",
    "        Get values for a series, indexed by sample timestamps\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        series\n",
    "        timestamps\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        results : pd.DataFrame\n",
    "        \"\"\"\n",
    "        series = series.query(\"`log_time_s` in @timestamps\")\n",
    "        return series.reindex(timestamps, fill_value=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def _similarity(s1, s2):\n",
    "        \"\"\"\n",
    "        Compute the cosine similarity between the two series.\n",
    "        Parameters\n",
    "        ----------\n",
    "        s1 : np.ndarray\n",
    "        s2 : np.ndarray\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        similarity : np.float64\n",
    "        \"\"\"\n",
    "        if s1.shape[0] == 0 or s2.shape[0] == 0:\n",
    "            return 0\n",
    "        # Reshape because we only have a single feature, the count.\n",
    "        arr1 = s1.reshape(-1, 1)\n",
    "        arr2 = s2.reshape(-1, 1)\n",
    "        # Compute the cosine similarity.\n",
    "        return sklearn.metrics.pairwise.cosine_similarity(arr1, arr2)[0][0]\n",
    "\n",
    "    @staticmethod\n",
    "    def _sample_timestamps(n, start_time, end_time, n_samples, interval):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n : int\n",
    "        start_time : pd.Timestamp\n",
    "        end_time : pd.Timestamp\n",
    "        n_samples : int\n",
    "        interval : pd.TimeDelta\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        samples : pd.DatetimeArray\n",
    "            Array of timestamps that were sampled.\n",
    "        \"\"\"\n",
    "        if n > n_samples:\n",
    "            offsets = np.random.choice(a=n, size=n_samples, replace=False)\n",
    "        else:\n",
    "            offsets = np.arange(n)\n",
    "        timestamps = []\n",
    "        for offset in offsets:\n",
    "            next_time = start_time + interval * offset\n",
    "            if next_time >= end_time:\n",
    "                break\n",
    "            timestamps.append(next_time)\n",
    "        return pd.array(timestamps)\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_neighbors(centers, timestamps, n_neighbors):\n",
    "        \"\"\"\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        centers\n",
    "        timestamps\n",
    "        n_neighbors\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        neighbors : sklearn.neighbors.NearestNeighbors | None\n",
    "        \"\"\"\n",
    "        clusters = sorted(centers.keys())\n",
    "        samples = np.array([Clusterer._query_series(centers[cluster], timestamps).values for cluster in clusters])\n",
    "\n",
    "        if len(samples) == 0:\n",
    "            neighbors = None\n",
    "        else:\n",
    "            samples = samples.reshape(len(clusters), -1)\n",
    "            normalized_samples = sklearn.preprocessing.normalize(samples, copy=False)\n",
    "            neighbors = sklearn.neighbors.NearestNeighbors(n_neighbors=n_neighbors, algorithm=\"kd_tree\", metric=\"l2\")\n",
    "            neighbors.fit(normalized_samples)\n",
    "        return neighbors\n",
    "\n",
    "    def _modify_cluster(self, positive, cluster, template, start_time, end_time):\n",
    "        \"\"\"Add or remove a template from a cluster.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        positive : bool\n",
    "            True for add, False for remove.\n",
    "        cluster : int\n",
    "            The Cluster to modify.\n",
    "        template : string\n",
    "            Template to add to or remove from.\n",
    "        start_time, end_time : pd.Timestamp\n",
    "            Current time range considered\n",
    "        \"\"\"\n",
    "        modify_method = self.centers[cluster].add if positive else self.centers[cluster].sub\n",
    "\n",
    "        self.centers[cluster] = modify_method(\n",
    "            self._query_df_range(self._df, template, start_time, end_time), fill_value=0\n",
    "        )\n",
    "        self.cluster_sizes[cluster] += 1 if positive else -1\n",
    "\n",
    "    def _adjust_template(self, template, current_time, old_assignment, timestamps, neighbors):\n",
    "        \"\"\"Adjust template cluster assignment at current time.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        template : string\n",
    "            The query template we need to update.\n",
    "        current_time : pd.Timestamp\n",
    "            Timestamp of the current clustering iteration.\n",
    "        old_assignment : int\n",
    "            Template's previous cluster assignment.\n",
    "        timestamps : np.array(pd.Timestamp)\n",
    "            Array of timestamps to sample from the centers fo similarity measurement.\n",
    "        neighbors : sklearn.neighbors.NearestNeighbors\n",
    "            Nearest neighbor learner containing all the cluster centers.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        The updated cluster assignment to be added to self.assignments.\n",
    "        \"\"\"\n",
    "        end_time = current_time + self.cluster_gap * self.interval_delta\n",
    "        # Only consider the last 10 seconds.\n",
    "        start_time = max(self.min_time, end_time - datetime.timedelta(seconds=10))\n",
    "\n",
    "        # If template has not appeared at this point in time; assignment is still None.\n",
    "        if (old_assignment is None) and (current_time <= self._get_first_arrival(template)):\n",
    "            return None\n",
    "        if old_assignment is not None:\n",
    "            # Template is the last member of the cluster.\n",
    "            last_cluster_element = self.cluster_sizes[old_assignment] == 1\n",
    "            # Template still belongs to its old cluster.\n",
    "            still_belongs = (\n",
    "                Clusterer._similarity(\n",
    "                    self._query_df(self._df, template, timestamps).values,\n",
    "                    self._query_series(self.centers[old_assignment], timestamps).values,\n",
    "                )\n",
    "                > self.rho\n",
    "            )\n",
    "            # If the template still belongs.\n",
    "            if last_cluster_element or still_belongs:\n",
    "                # reason = ('L' if last_cluster_element else '') + ('B' if still_belongs else '')\n",
    "                # print(f'Template stayed in cluster {old_cluster} because ({reason}): {self._dbgname[template]}')\n",
    "                return old_assignment\n",
    "\n",
    "            # Otherwise, eliminate the template from its old cluster.\n",
    "            self._modify_cluster(False, old_assignment, template, start_time, end_time)\n",
    "            # print(f'Template eliminated from cluster {old_cluster}: {self._dbgname[template]}')\n",
    "\n",
    "        new_assignment = None\n",
    "        # Try to find a cluster membership for the template.\n",
    "        if neighbors is None:\n",
    "            for cluster in self.centers.keys():\n",
    "                if (\n",
    "                    self._similarity(\n",
    "                        self._query_df(self._df, template, timestamps).values,\n",
    "                        self._query_series(self.centers[cluster], timestamps).values,\n",
    "                    )\n",
    "                    > self.rho\n",
    "                ):\n",
    "                    new_assignment = cluster\n",
    "                    break\n",
    "        else:\n",
    "            data = self._query_df(self._df, template, timestamps)[\"count\"].values.reshape(1, -1)\n",
    "            data = sklearn.preprocessing.normalize(data)\n",
    "            neighbor = neighbors.kneighbors(data, return_distance=False)[0][0]\n",
    "            clusters = sorted(self.centers.keys())\n",
    "            if self._similarity(data, self.centers[clusters[neighbor]].values) > self.rho:\n",
    "                new_assignment = clusters[neighbor]\n",
    "\n",
    "        # If this template found a cluster to join, then make the assignment and continue.\n",
    "        if new_assignment is not None:\n",
    "            # description = 'joined' if old_assignment is None else 'reassigned to'\n",
    "            # print(f'Template {description} cluster {new_cluster}: {self._dbgname[template]}')\n",
    "            self._modify_cluster(True, new_assignment, template, start_time, end_time)\n",
    "            return new_assignment\n",
    "\n",
    "        # Otherwise, this template needs a new cluster. Make a new cluster.\n",
    "        new_assignment = self.next_cluster\n",
    "        self.next_cluster += 1\n",
    "\n",
    "        self.centers[new_assignment] = self._query_df_range(self._df, template, start_time, end_time)\n",
    "        assert self.centers[new_assignment].index.name == \"log_time_s\"\n",
    "        assert self.centers[new_assignment].columns.values == [\"count\"]\n",
    "        if self.centers[new_assignment].shape[0] == 0:\n",
    "            print(\n",
    "                f\"WARNING: cluster {new_assignment} has no items.\"\n",
    "                f\"Does the following query appear within the lookback window:\"\n",
    "                f\"{self._dbgname[template]}\"\n",
    "            )\n",
    "\n",
    "        self.cluster_sizes[new_assignment] = 1\n",
    "        self.cluster_totals[new_assignment] = 0\n",
    "        print(f\"Created cluster {new_assignment} based on template: {self._dbgname[template]}\")\n",
    "        return new_assignment\n",
    "\n",
    "    def _cluster_online(self):\n",
    "        # Map cluster id to df representing center of cluster.\n",
    "        self.centers: Dict[int, pd.DataFrame] = {}\n",
    "        self.cluster_totals: Dict[int, int] = {}\n",
    "        self.cluster_sizes: Dict[int, int] = {}\n",
    "\n",
    "        # Array representing the assignment of template to clusters at a given time.\n",
    "        self.assignments = [(self.min_time, {template: None for template in sorted(self._get_queries())},)]\n",
    "\n",
    "        # Begin at min time with no assignments.\n",
    "        current_time = self.min_time\n",
    "\n",
    "        # The next cluster id to use.\n",
    "        self.next_cluster = 0\n",
    "\n",
    "        for gap in range(self.n_gaps):\n",
    "            # End time is the next interval.\n",
    "            next_time = current_time + self.cluster_gap * self.interval_delta\n",
    "            # Only consider the last 10 seconds.\n",
    "            start_time = max(self.min_time, next_time - datetime.timedelta(seconds=10))\n",
    "            # Timestamps to consider.\n",
    "            timestamps = self._sample_timestamps(self.n, start_time, next_time, self.n_samples, self.interval_delta)\n",
    "\n",
    "            # Get assignment dicts.\n",
    "            last_assignment = self.assignments[-1][1]\n",
    "            assignment = last_assignment.copy()\n",
    "\n",
    "            # Update counts for all the assignments made in the past round.\n",
    "            for template in last_assignment:\n",
    "                old_assignment = last_assignment[template]\n",
    "                if old_assignment is not None:\n",
    "                    counts = self._query_df_range(self._df, template, current_time, next_time)\n",
    "                    self.centers[old_assignment] = self.centers[old_assignment].add(counts, fill_value=0)\n",
    "                    self.cluster_totals[old_assignment] += counts.sum().values[0]\n",
    "\n",
    "            # If possible, build a kdtree of neighbors.\n",
    "            neighbors = self._build_neighbors(self.centers, timestamps, n_neighbors=1)\n",
    "\n",
    "            # For each template, try to assign a cluster.\n",
    "            for template in self._get_queries():\n",
    "                assignment[template] = self._adjust_template(\n",
    "                    template=template,\n",
    "                    current_time=current_time,\n",
    "                    old_assignment=last_assignment[template],\n",
    "                    timestamps=timestamps,\n",
    "                    neighbors=neighbors,\n",
    "                )\n",
    "\n",
    "            # If possible, build an updated kdtree of neighbors. we need n_neighbors=2\n",
    "            # because our query points are centers, so the second closest neighbor is the merge candidate.\n",
    "            neighbors = self._build_neighbors(self.centers, timestamps, n_neighbors=2)\n",
    "            root = [None] * len(self.centers)\n",
    "            clusters = sorted(self.centers.keys())\n",
    "            if len(clusters) > 1:\n",
    "                # Try to merge clusters.\n",
    "                for i, cluster in enumerate(clusters):\n",
    "                    merge_cluster = None\n",
    "                    data = self._query_series(self.centers[cluster], timestamps)[\"count\"].values.reshape(1, -1)\n",
    "                    data = sklearn.preprocessing.normalize(data)\n",
    "                    neighbor = neighbors.kneighbors(data, return_distance=False)\n",
    "\n",
    "                    neighbor_inds = neighbor[0]\n",
    "                    if clusters[neighbor_inds[0]] == cluster:\n",
    "                        neighbor = neighbor_inds[1]\n",
    "                    else:\n",
    "                        neighbor = neighbor_inds[0]\n",
    "                    while root[neighbor] is not None:\n",
    "                        neighbor = root[neighbor]\n",
    "                    is_similar = (\n",
    "                        self._similarity(\n",
    "                            self._query_series(self.centers[cluster], timestamps).values,\n",
    "                            self._query_series(self.centers[clusters[neighbor]], timestamps).values,\n",
    "                        )\n",
    "                        > self.rho\n",
    "                    )\n",
    "                    if cluster != clusters[neighbor] and is_similar:\n",
    "                        merge_cluster = clusters[neighbor]\n",
    "                    if merge_cluster is not None:\n",
    "                        self.centers[merge_cluster] = self.centers[merge_cluster].add(\n",
    "                            self.centers[cluster], fill_value=0\n",
    "                        )\n",
    "                        self.cluster_sizes[merge_cluster] += self.cluster_sizes[cluster]\n",
    "                        del self.centers[cluster]\n",
    "                        del self.cluster_sizes[cluster]\n",
    "                        if neighbors is not None:\n",
    "                            root[i] = neighbor\n",
    "                        for template in self._get_queries():\n",
    "                            if assignment[template] == cluster:\n",
    "                                assignment[template] = merge_cluster\n",
    "                                print(\n",
    "                                    f\"Template merged from cluster {cluster} into {merge_cluster}: \"\n",
    "                                    f\"{self._dbgname[template]}\"\n",
    "                                )\n",
    "            self.assignments.append((next_time, assignment))\n",
    "            current_time = next_time\n",
    "            for cluster, df in self.centers.items():\n",
    "                if df.shape[0] == 0:\n",
    "                    print(f\"WARNING: gap {gap} cluster {cluster} has no items.\")\n",
    "        for template, cluster in self.assignments[-1][1].items():\n",
    "            print(self._dbgname[template], \"->\", cluster)\n",
    "        self.num_clusters = len(self.centers)\n",
    "\n",
    "    def _cluster_offline(self):\n",
    "        next_time = self.max_time + self.cluster_gap * self.interval_delta\n",
    "        # TODO(Mike): only consider the last 10 seconds? or sample everything?\n",
    "        start_time = self.min_time\n",
    "        # Sample timestamps to consider.\n",
    "        timestamps = self._sample_timestamps(self.n, start_time, next_time, self.n_samples, self.interval_delta)\n",
    "        counts = np.array(\n",
    "            [\n",
    "                # Create (k,n) matrix where there are\n",
    "                # k templates, n_sample features for DBSCAN.\n",
    "                self._query_df(self._df, template, timestamps).values.reshape((-1))\n",
    "                for template in self._get_queries()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        clustering = DBSCAN(eps=1 - self.rho, metric=\"cosine\", min_samples=1).fit(counts)\n",
    "        labels = clustering.labels_\n",
    "        reverse_lookup = {template_id: template_str for template_str, template_id in self._dbgname.items()}\n",
    "        final_assignments = {reverse_lookup[template_id]: cluster_id for template_id, cluster_id in enumerate(labels)}\n",
    "        return pd.DataFrame(final_assignments.items(), columns=[\"query_template\", \"cluster\"]).set_index(\n",
    "            \"query_template\"\n",
    "        )\n",
    "\n",
    "\n",
    "def get_grouped_dataframe_interval(df, interval=None):\n",
    "    \"\"\"\n",
    "        Get the pre-grouped version of query log data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        interval : pd.TimeDelta or None\n",
    "            time interval to group and count the query templates\n",
    "            if None, pd is only aggregated by template\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        grouped_df : pd.DataFrame\n",
    "            Dataframe containing the pre-grouped query log data.\n",
    "            Grouped on query template and optionally log time.\n",
    "        \"\"\"\n",
    "    gb = None\n",
    "    if interval is None:\n",
    "        gb = df.groupby(\"query_template\").size()\n",
    "        gb.drop(\"\", axis=0, inplace=True)\n",
    "    else:\n",
    "        gb = df.groupby(\"query_template\").resample(interval).size()\n",
    "        # gb.drop(\"\", axis=0, level=0, inplace=True)\n",
    "    grouped_df = pd.DataFrame(gb, columns=[\"count\"])\n",
    "    return grouped_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering query templates.\n",
      "Generating cluster assignments.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_template</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SELECT * FROM period_application WHERE period_id = $1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELECT * FROM period_umbrella WHERE period_id = $1 LIMIT $2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELECT department_unit.* FROM department_unit WHERE unit_id = $1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELECT domain_unit.* FROM domain_unit WHERE domain_id = $1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELECT domain_unit.* FROM domain_unit WHERE unit_id = $1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELECT expdate,expdate2 FROM systemenv where domain_id=$1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELECT name from domain where id = $1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELECT period.* FROM period WHERE period_id = $1 ORDER BY period_id DESC</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELECT period.* FROM period WHERE unit_id = $1 AND parent_period_id = $2 ORDER BY period_id DESC</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELECT period.* FROM period WHERE unit_id = $1 AND period_type_id = $2 ORDER BY period_id DESC</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELECT period_program.* FROM period_program WHERE period_id = $1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELECT program.* FROM program WHERE program.unit_id = $1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELECT program_group.* FROM program_group WHERE period_id = $1 ORDER BY program_group_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELECT programs.id FROM programs INNER JOIN lu_programs_departments ON programs.id = lu_programs_departments.program_id INNER JOIN lu_domain_department ON lu_programs_departments.department_id = lu_domain_department.department_id WHERE programs.enabled = $1 AND lu_domain_department.domain_id = $2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELECT programs_unit.* FROM programs_unit WHERE unit_id = $1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELECT unit.* FROM unit WHERE parent_unit_id = $1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SELECT unit.* FROM unit WHERE unit_id = $1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>select content from content where name= $1 and domain_id=$2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    cluster\n",
       "query_template                                             \n",
       "SELECT * FROM period_application WHERE period_i...        0\n",
       "SELECT * FROM period_umbrella WHERE period_id =...        0\n",
       "SELECT department_unit.* FROM department_unit W...        0\n",
       "SELECT domain_unit.* FROM domain_unit WHERE dom...        0\n",
       "SELECT domain_unit.* FROM domain_unit WHERE uni...        0\n",
       "SELECT expdate,expdate2 FROM systemenv where do...        1\n",
       "SELECT name from domain where id = $1                     0\n",
       "SELECT period.* FROM period WHERE period_id = $...        0\n",
       "SELECT period.* FROM period WHERE unit_id = $1 ...        0\n",
       "SELECT period.* FROM period WHERE unit_id = $1 ...        0\n",
       "SELECT period_program.* FROM period_program WHE...        0\n",
       "SELECT program.* FROM program WHERE program.uni...        0\n",
       "SELECT program_group.* FROM program_group WHERE...        0\n",
       "SELECT programs.id FROM programs INNER JOIN lu_...        0\n",
       "SELECT programs_unit.* FROM programs_unit WHERE...        0\n",
       "SELECT unit.* FROM unit WHERE parent_unit_id = $1         0\n",
       "SELECT unit.* FROM unit WHERE unit_id = $1                0\n",
       "select content from content where name= $1 and ...        1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DEBUG_POSTGRESQL_CSV_PARSED, parse_dates=[\"log_time\"], index_col=[\"log_time\"])\n",
    "cluster_interval = pd.Timedelta(milliseconds=250)\n",
    "\n",
    "df = get_grouped_dataframe_interval(df, cluster_interval)\n",
    "\n",
    "df.index.rename([\"query_template\", \"log_time_s\"], inplace=1)\n",
    "print(\"Clustering query templates.\")\n",
    "clusterer = Clusterer(df, cluster_interval=cluster_interval)\n",
    "print(\"Generating cluster assignments.\")\n",
    "clusterer.assignment_df[:20]\n",
    "# clusterer.assignment_df.to_parquet(output_parquet)\n",
    "# print(\"Done!\")\n",
    "\n",
    "# df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from model import LSTM, ForecastDataset\n",
    "from plumbum import cli\n",
    "from preprocessor import Preprocessor\n",
    "\n",
    "\n",
    "class ClusterForecaster:\n",
    "    \"\"\"\n",
    "    Predict cluster in workload using trained LSTMs.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    prediction_interval : pd.Timedelta\n",
    "        Time interval to aggregate cluster counts by.\n",
    "    prediction_horizon : pd.Timedelta\n",
    "        The prediction horizon of the models to train.\n",
    "    prediction_seqlen : int\n",
    "        Number of intervals to feed the LSTM for a prediction.\n",
    "    models : Dict[int, LSTM]\n",
    "        Dictionary of trained models to perform inference by\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    MODEL_PREFIX = \"model_\"\n",
    "\n",
    "    @staticmethod\n",
    "    def cluster_to_file(path, cluster):\n",
    "        \"\"\"Generate model file path from cluster name\"\"\"\n",
    "        return f\"{path}/{ClusterForecaster.MODEL_PREFIX}{cluster}.pkl\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_cluster_from_file(filename):\n",
    "        \"\"\"Infer cluster id from file name\"\"\"\n",
    "        m = re.search(f\"(?<={ClusterForecaster.MODEL_PREFIX})[^/]*(?=\\\\.pkl)\", filename)\n",
    "        if m is None:\n",
    "            raise RuntimeError(\"Could not get cluster name\")\n",
    "        return m[0]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df,\n",
    "        prediction_seqlen,\n",
    "        prediction_interval,\n",
    "        prediction_horizon,\n",
    "        save_path,\n",
    "        top_k=5,\n",
    "        override=False,\n",
    "    ):\n",
    "        \"\"\"Construct the ClusterForecaster object.\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_df : pd.DataFrame\n",
    "            Training data grouped by cluster and timestamp\n",
    "        save_path : str\n",
    "            Directory for loading/saving trained models\n",
    "        top_k : int\n",
    "            Only train models for the top k most common clusters.\n",
    "        override : bool\n",
    "            Determines whether we should (re)train models anyway, even if they are\n",
    "            in the directory.\n",
    "        \"\"\"\n",
    "        assert train_df.index.names[0] == \"cluster\"\n",
    "        assert train_df.index.names[1] == \"log_time_s\"\n",
    "\n",
    "        self.prediction_seqlen = prediction_seqlen\n",
    "        self.prediction_interval = prediction_interval\n",
    "        self.prediction_horizon = prediction_horizon\n",
    "        self.models = {}\n",
    "\n",
    "        if not override:\n",
    "            model_files = glob.glob(str(Path(save_path) / f\"{self.MODEL_PREFIX}*.pkl\"))\n",
    "            for filename in model_files:\n",
    "                cluster_name = self.get_cluster_from_file(filename)\n",
    "                self.models[int(cluster_name)] = LSTM.load(filename)\n",
    "                print(f\"loaded model for cluster {cluster_name}\")\n",
    "            print(f\"Loaded {len(model_files)} models\")\n",
    "\n",
    "        if train_df is None:\n",
    "            return\n",
    "\n",
    "        # Only consider top k clusters.\n",
    "        cluster_totals = train_df.groupby(level=0).sum().sort_values(by=\"count\", ascending=False)\n",
    "        labels = cluster_totals.index[:top_k]\n",
    "\n",
    "        print(\"Training on cluster time series..\")\n",
    "\n",
    "        mintime = train_df.index.get_level_values(1).min()\n",
    "        maxtime = train_df.index.get_level_values(1).max()\n",
    "\n",
    "        dtindex = pd.DatetimeIndex([mintime, maxtime])\n",
    "\n",
    "        for cluster in labels:\n",
    "            if cluster in self.models and not override:\n",
    "                print(f\"Already have model for cluster {cluster}, skipping\")\n",
    "                continue\n",
    "\n",
    "            print(f\"training model for cluster {cluster}\")\n",
    "            cluster_counts = train_df[train_df.index.get_level_values(0) == cluster].droplevel(0)\n",
    "\n",
    "            # This zero-fills the start and ends of the cluster time series.\n",
    "            cluster_counts = cluster_counts.reindex(cluster_counts.index.append(dtindex), fill_value=0)\n",
    "            cluster_counts = cluster_counts.resample(prediction_interval).sum()\n",
    "            self._train_cluster(cluster_counts, cluster, save_path)\n",
    "\n",
    "    def _train_cluster(self, cluster_counts, cluster, save_path):\n",
    "        dataset = ForecastDataset(\n",
    "            cluster_counts,\n",
    "            sequence_length=self.prediction_seqlen,\n",
    "            horizon=self.prediction_horizon,\n",
    "            interval=self.prediction_interval,\n",
    "        )\n",
    "\n",
    "        self.models[cluster] = LSTM(\n",
    "            horizon=self.prediction_horizon,\n",
    "            interval=self.prediction_interval,\n",
    "            sequence_length=self.prediction_seqlen,\n",
    "        )\n",
    "\n",
    "        self.models[cluster].fit(dataset)\n",
    "        self.models[cluster].save(self.cluster_to_file(save_path, cluster))\n",
    "\n",
    "    def predict(self, cluster_df, cluster, start_time, end_time):\n",
    "        \"\"\"\n",
    "        Given a cluster dataset, attempt to return prediction of query count\n",
    "        from a cluster within the given time-range.\n",
    "        \"\"\"\n",
    "        assert cluster_df.index.names[0] == \"cluster\"\n",
    "        assert cluster_df.index.names[1] == \"log_time_s\"\n",
    "\n",
    "        # Cluster not in the data.\n",
    "        if cluster not in cluster_df.index.get_level_values(0):\n",
    "            return None\n",
    "\n",
    "        # No model for given cluster.\n",
    "        if cluster not in self.models.keys():\n",
    "            return None\n",
    "\n",
    "        cluster_counts = cluster_df[cluster_df.index.get_level_values(0) == cluster].droplevel(0)\n",
    "\n",
    "        # Truncate cluster_df to the time range necessary to generate prediction range.\n",
    "\n",
    "        # TODO(Mike): Right now, if the sequence required to predict a certain interval\n",
    "        # is not present in the data, we simply do not make any predictions (i.e. return 0)\n",
    "        # Should we produce a warning/error so the user is aware there is insufficient\n",
    "        # data?\n",
    "        trunc_start = start_time - self.prediction_horizon - (self.prediction_seqlen) * self.prediction_interval\n",
    "        trunc_end = end_time - self.prediction_horizon\n",
    "\n",
    "        truncated = cluster_counts[(cluster_counts.index >= trunc_start) & (cluster_counts.index < trunc_end)]\n",
    "\n",
    "        dataset = ForecastDataset(\n",
    "            truncated,\n",
    "            sequence_length=self.prediction_seqlen,\n",
    "            horizon=self.prediction_horizon,\n",
    "            interval=self.prediction_interval,\n",
    "        )\n",
    "\n",
    "        # generate predictions\n",
    "        predictions = [self.models[cluster].predict(seq) for seq, _ in dataset]\n",
    "\n",
    "        # tag with timestamps\n",
    "        pred_arr = [[dataset.get_y_timestamp(i), pred] for i, pred in enumerate(predictions)]\n",
    "\n",
    "        pred_df = pd.DataFrame(pred_arr, columns=[\"log_time_s\", \"count\"])\n",
    "        pred_df.set_index(\"log_time_s\", inplace=True)\n",
    "        return pred_df[start_time:]\n",
    "\n",
    "\n",
    "class WorkloadGenerator:\n",
    "    \"\"\"\n",
    "    Use preprocessed query template/params and cluster to generate\n",
    "    representative workload.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, preprocessor, assignment_df):\n",
    "        df = preprocessor.get_grouped_dataframe_interval()\n",
    "\n",
    "        # Join to cluster and group by.\n",
    "        joined = df.join(assignment_df)\n",
    "\n",
    "        # Calculate weight of template within each cluster.\n",
    "        joined[\"cluster\"].fillna(-1, inplace=True)\n",
    "        summed = joined.groupby([\"cluster\", \"query_template\"]).sum()\n",
    "        self._preprocessor = preprocessor\n",
    "        self._percentages = summed / summed.groupby(level=0).sum()\n",
    "\n",
    "    def get_workload(self, cluster, cluster_count):\n",
    "        \"\"\"Given a cluster id and a sample size, produce a \"sample\" workload,\n",
    "        sampling from the preprocessed queries.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cluster : int\n",
    "            The cluster to generate for\n",
    "        cluster_count : scalar\n",
    "            The number of queries to sample\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        predicted_queries : pd.Dataframe\n",
    "            A sampled workload in the form of (query, count) pairs\n",
    "        \"\"\"\n",
    "\n",
    "        templates = self._percentages[self._percentages.index.get_level_values(0) == cluster].droplevel(0)\n",
    "        templates = templates * cluster_count\n",
    "\n",
    "        # TODO(Mike): The true sample of parameters might be too inefficient,\n",
    "        # But using the same parameters for all queries is not representative enough.\n",
    "\n",
    "        # True sample of parameters.\n",
    "        # templates_with_param_vecs = [\n",
    "        #     (template, self._preprocessor.sample_params(template, int(count)))\n",
    "        #     for template, count in zip(templates.index.values, templates.values)\n",
    "        # ]\n",
    "\n",
    "        # Sample parameters once. Then use the same parameters\n",
    "        # for all queries in the query template.\n",
    "        templates_with_param_vecs = [\n",
    "            (\n",
    "                template,\n",
    "                np.tile(self._preprocessor.sample_params(template, 1)[0], (int(count), 1)),\n",
    "            )\n",
    "            for template, count in zip(templates.index.values, templates.values)\n",
    "        ]\n",
    "\n",
    "        workload = [\n",
    "            self._preprocessor.substitute_params(template, param_vec)\n",
    "            for template, param_vecs in templates_with_param_vecs\n",
    "            for param_vec in param_vecs\n",
    "        ]\n",
    "        workload = pd.DataFrame(workload, columns=[\"query\"])\n",
    "        predicted_queries = workload.groupby(\"query\").size().sort_values(ascending=False)\n",
    "\n",
    "        return predicted_queries\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading postgres log...\n",
      "reading cluster assignments.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th>log_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">0</th>\n",
       "      <th>2017-06-25 07:18:33.750</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:34.000</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:34.250</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:34.500</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:34.750</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:35.000</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:35.250</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:35.500</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:35.750</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2017-06-25 07:18:29.750</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2017-06-25 07:18:23.750</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>2017-06-25 07:18:28.750</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">4</th>\n",
       "      <th>2017-06-25 07:18:19.750</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:20.000</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:20.250</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:20.500</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:20.750</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">5</th>\n",
       "      <th>2017-06-25 07:18:32.750</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:33.000</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:33.250</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:33.500</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:33.750</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:34.000</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:34.250</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:34.500</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:34.750</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:35.000</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:35.250</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:35.500</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-25 07:18:35.750</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>2017-06-25 07:18:31.750</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>2017-06-25 07:18:25.750</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>2017-06-25 07:18:30.750</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>2017-06-25 07:18:27.750</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>2017-06-25 07:18:24.750</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 count\n",
       "cluster log_time                      \n",
       "0       2017-06-25 07:18:33.750      5\n",
       "        2017-06-25 07:18:34.000      0\n",
       "        2017-06-25 07:18:34.250      0\n",
       "        2017-06-25 07:18:34.500      0\n",
       "        2017-06-25 07:18:34.750      5\n",
       "        2017-06-25 07:18:35.000      0\n",
       "        2017-06-25 07:18:35.250      0\n",
       "        2017-06-25 07:18:35.500      0\n",
       "        2017-06-25 07:18:35.750      3\n",
       "1       2017-06-25 07:18:29.750      1\n",
       "2       2017-06-25 07:18:23.750      1\n",
       "3       2017-06-25 07:18:28.750      1\n",
       "4       2017-06-25 07:18:19.750      1\n",
       "        2017-06-25 07:18:20.000      0\n",
       "        2017-06-25 07:18:20.250      0\n",
       "        2017-06-25 07:18:20.500      0\n",
       "        2017-06-25 07:18:20.750      1\n",
       "5       2017-06-25 07:18:32.750      1\n",
       "        2017-06-25 07:18:33.000      0\n",
       "        2017-06-25 07:18:33.250      0\n",
       "        2017-06-25 07:18:33.500      0\n",
       "        2017-06-25 07:18:33.750      1\n",
       "        2017-06-25 07:18:34.000      0\n",
       "        2017-06-25 07:18:34.250      0\n",
       "        2017-06-25 07:18:34.500      0\n",
       "        2017-06-25 07:18:34.750      0\n",
       "        2017-06-25 07:18:35.000      0\n",
       "        2017-06-25 07:18:35.250      0\n",
       "        2017-06-25 07:18:35.500      0\n",
       "        2017-06-25 07:18:35.750      1\n",
       "6       2017-06-25 07:18:31.750      1\n",
       "7       2017-06-25 07:18:25.750      1\n",
       "8       2017-06-25 07:18:30.750      1\n",
       "9       2017-06-25 07:18:27.750      1\n",
       "10      2017-06-25 07:18:24.750      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading postgres log...\")\n",
    "df = pd.read_csv(DEBUG_POSTGRESQL_CSV_PARSED, parse_dates=[\"log_time\"], index_col=[\"log_time\"])\n",
    "cluster_interval = pd.Timedelta(milliseconds=250)\n",
    "df = get_grouped_dataframe_interval(df, cluster_interval)\n",
    "\n",
    "print(\"reading cluster assignments.\")\n",
    "assignment_df = clusterer.assignment_df\n",
    "\n",
    "# Join to cluster and group by (cluster,time).\n",
    "joined = df.join(assignment_df)\n",
    "joined[\"cluster\"].fillna(-1, inplace=True)\n",
    "clustered_df = joined.groupby([\"cluster\", \"log_time\"]).sum()\n",
    "\n",
    "clustered_df\n",
    "\n",
    "\n",
    "# TODO(MIKE): check how many templates are not part of known\n",
    "# clusters (i.e. cluster = -1).\n",
    "# forecaster = ClusterForecaster(\n",
    "#     clustered_df,\n",
    "#     prediction_seqlen=self.pred_seqlen,\n",
    "#     prediction_interval=self.pred_interval,\n",
    "#     prediction_horizon=self.pred_horizon,\n",
    "#     save_path=self.model_path,\n",
    "#     override=self.override,\n",
    "# )\n",
    "\n",
    "# # Use preprocessor to sample template and parameter distributions.\n",
    "# wg = WorkloadGenerator(preprocessor, assignment_df)\n",
    "# clusters = set(assignment_df[\"cluster\"].values)\n",
    "\n",
    "# cluster_predictions = []\n",
    "# for cluster in clusters:\n",
    "#     start_time = pd.Timestamp(self.start_ts)\n",
    "#     end_time = pd.Timestamp(self.end_ts)\n",
    "#     pred_df = forecaster.predict(clustered_df, cluster, start_time, end_time)\n",
    "#     if pred_df is None:\n",
    "#         # No data or model for cluster.\n",
    "#         continue\n",
    "#     prediction_count = pred_df[\"count\"].sum()\n",
    "#     print(f\"Prediction for {cluster}: {prediction_count}\")\n",
    "#     cluster_predictions.append(wg.get_workload(cluster, prediction_count))\n",
    "\n",
    "# predicted_queries = pd.concat(cluster_predictions)\n",
    "# predicted_queries.to_csv(self.output_csv, header=None, quoting=csv.QUOTE_ALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d4f39e0e8945dc85ebf8adbc1053c185ae86818447b4d946a2f79d15397e919"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('db')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
